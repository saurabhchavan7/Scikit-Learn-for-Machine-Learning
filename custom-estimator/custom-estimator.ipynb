{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0539e9d-d54d-4c56-923a-0ae78942583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "from sklearn.utils import check_X_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e7ac1-1a20-4267-a794-611a9340f303",
   "metadata": {},
   "source": [
    "## Custom Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2d4b612-593b-4afc-a620-f5bbf16f4432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostFrequentClassClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.most_frequent_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # Validate input X and target vector y\n",
    "        X, y = check_X_y(X, y)\n",
    "\n",
    "        # Ensure y is 1D\n",
    "        y = np.ravel(y)\n",
    "\n",
    "        # Manually compute the most frequent class\n",
    "        unique_classes, counts = np.unique(y, return_counts=True)\n",
    "        self.most_frequent_ = unique_classes[np.argmax(counts)]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.most_frequent_ is None:\n",
    "            raise ValueError(\"This classifier instance is not fitted yet.\")\n",
    "        # Predict the most frequent class for each input sample\n",
    "        return np.full(shape=(X.shape[0],), fill_value=self.most_frequent_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397b7bc8-e10b-490b-9afe-9731eca3234b",
   "metadata": {},
   "source": [
    "### Explanation of Custom Estimator Code\n",
    "\n",
    "#### Class Definition\n",
    "The `MostFrequentClassClassifier` class is defined as a custom estimator in scikit-learn, extending `BaseEstimator` and `ClassifierMixin`.\n",
    "\n",
    "#### `__init__` Method\n",
    "- **Purpose:** Initializes an instance of the `MostFrequentClassClassifier` class.\n",
    "- **Attributes:**\n",
    "  - `self.most_frequent_`: Initially set to `None`, it will later store the most frequent class identified during fitting.\n",
    "\n",
    "#### `fit` Method\n",
    "- **Purpose:** Fits the model to the training data (`X`, `y`) and learns the most frequent class from `y`.\n",
    "- **Steps:**\n",
    "  1. **Input Validation:**\n",
    "     - Uses `check_X_y(X, y)` to validate and convert `X` and `y` into appropriate formats.\n",
    "  2. **Ensure `y` is 1D:**\n",
    "     - Converts `y` to a 1-dimensional array using `np.ravel(y)`.\n",
    "  3. **Compute Most Frequent Class:**\n",
    "     - Utilizes `np.unique(y, return_counts=True)` to find unique classes and their counts.\n",
    "     - Identifies the most frequent class by indexing into `unique_classes` using `np.argmax(counts)`.\n",
    "     - Stores the most frequent class in `self.most_frequent_`.\n",
    "  4. **Return Self:**\n",
    "     - Returns `self` after fitting.\n",
    "\n",
    "#### `predict` Method\n",
    "- **Purpose:** Predicts the most frequent class for new data samples `X`.\n",
    "- **Steps:**\n",
    "  1. **Check Fitted Status:**\n",
    "     - Raises a `ValueError` if `self.most_frequent_` is `None`, indicating the estimator has not been fitted.\n",
    "  2. **Prediction:**\n",
    "     - Returns an array of the most frequent class (`self.most_frequent_`) repeated for each sample in `X`, shaped `(X.shape[0],)`.\n",
    "\n",
    "#### Usage Note\n",
    "- **Functionality:** This custom estimator learns from the training data to predict the most frequent class for new data points.\n",
    "- **Extends:** Inherits functionalities from `BaseEstimator` and `ClassifierMixin`, providing compatibility with scikit-learn's API.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a932517-b9e2-4fdf-be93-b782ce0083d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class for all test instances: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Initialize and fit the custom estimator\n",
    "classifier = MostFrequentClassClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the custom estimator\n",
    "print(f\"Predicted class for all test instances: {predictions[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bddd981-3c09-4a96-ba19-a11cc198ef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae7ecbb-399a-4d6a-bf14-3df60c167b98",
   "metadata": {},
   "source": [
    "### Explanation of Code Snippet\n",
    "\n",
    "#### Loading Iris Dataset\n",
    "- **Purpose:** Loads the Iris dataset using `load_iris()` from `sklearn.datasets`.\n",
    "- **Variables:**\n",
    "  - `iris`: Contains the loaded dataset.\n",
    "  - `X, y`: Assigns features (`X`) and target labels (`y`) from the loaded dataset (`iris.data`, `iris.target`).\n",
    "\n",
    "#### Splitting the Data\n",
    "- **Purpose:** Splits the dataset into training and testing sets using `train_test_split()`.\n",
    "- **Variables:**\n",
    "  - `X_train, X_test, y_train, y_test`: Holds the training and testing subsets of features (`X_train`, `X_test`) and target labels (`y_train`, `y_test`).\n",
    "\n",
    "#### Initializing and Fitting Custom Estimator\n",
    "- **Purpose:** Creates an instance of the `MostFrequentClassClassifier` custom estimator.\n",
    "- **Steps:**\n",
    "  - Initializes `classifier` as an object of `MostFrequentClassClassifier()`.\n",
    "  - Fits `classifier` using `X_train` and `y_train` via `classifier.fit(X_train, y_train)`.\n",
    "\n",
    "#### Making Predictions\n",
    "- **Purpose:** Uses the fitted `classifier` to predict target labels for `X_test`.\n",
    "- **Steps:**\n",
    "  - Predicts `predictions` using `classifier.predict(X_test)`.\n",
    "\n",
    "#### Evaluating the Custom Estimator\n",
    "- **Purpose:** Prints the predicted class for the first instance in `X_test`.\n",
    "- **Output:**\n",
    "  - Displays the predicted class using `print(f\"Predicted class for all test instances: {predictions[0]}\")`.\n",
    "\n",
    "#### Summary\n",
    "- **Functionality:** Demonstrates a workflow using a custom estimator (`MostFrequentClassClassifier`) to fit, predict, and evaluate on the Iris dataset.\n",
    "- **Integration:** Integrates seamlessly with scikit-learn's API, showcasing compatibility and usage with standard scikit-learn functions like `train_test_split`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abca9f66-006d-466e-8093-35bea32466a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.most_frequent_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda6af4f-dcaf-4550-a645-017a7b3afffd",
   "metadata": {},
   "source": [
    "### Explanation of `classifier.most_frequent_`\n",
    "\n",
    "#### Purpose\n",
    "- **Objective:** `classifier.most_frequent_` is an attribute of the `MostFrequentClassClassifier` custom estimator.\n",
    "- **Function:** It stores the most frequent class that was determined during the fitting process using the `fit()` method of the custom estimator.\n",
    "\n",
    "#### Usage\n",
    "- **During Fitting:** When the `fit()` method of `MostFrequentClassClassifier` is called, `classifier.most_frequent_` is computed.\n",
    "  - **Computing Process:** The `fit()` method calculates the most frequent class by analyzing the target labels (`y`) provided during training.\n",
    "  - **Storage:** The computed most frequent class is stored in `classifier.most_frequent_` for later use during predictions.\n",
    "\n",
    "#### Accessing Predictions\n",
    "- **During Prediction:** When `predict()` method is called on `classifier`, `classifier.most_frequent_` is used to predict the class for new data points.\n",
    "  - **Predicting Process:** `predict()` method utilizes `classifier.most_frequent_` to fill the prediction array with the most frequent class determined during training.\n",
    "  - **Output:** The predictions are generated based on this stored value, ensuring consistent results across all test instances.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a03636b-26c6-4bf9-9000-e32d7f662113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34782609, 0.34782609, 0.31818182, 0.36363636, 0.36363636])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(classifier, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e574c3f-5f6d-4454-b45f-185a78137210",
   "metadata": {},
   "source": [
    "### Explanation of `cross_val_score(classifier, X_train, y_train)`\n",
    "\n",
    "#### Purpose\n",
    "- **Objective:** `cross_val_score` is a function from `sklearn.model_selection` used to perform cross-validation for evaluating estimator performance.\n",
    "- **Parameters:** \n",
    "  - `classifier`: The estimator object (`MostFrequentClassClassifier` in this case) to be evaluated.\n",
    "  - `X_train`: Training data features.\n",
    "  - `y_train`: Training data labels.\n",
    "\n",
    "#### Cross-Validation Process\n",
    "- **Methodology:** \n",
    "  - **Splitting Data:** `X_train` and `y_train` are split into K folds (default 5 folds).\n",
    "  - **Training and Evaluation:** \n",
    "    - For each fold, the estimator (`classifier`) is trained on a subset of the data and tested on the remaining part.\n",
    "    - Performance metrics (accuracy in this case) are computed for each fold.\n",
    "  - **Aggregation:** \n",
    "    - The function returns an array of scores, where each score corresponds to the accuracy of the estimator on each fold of the cross-validation process.\n",
    "\n",
    "#### Output\n",
    "- **Output Array:** \n",
    "  - The array `[0.34782609, 0.34782609, 0.31818182, 0.36363636, 0.36363636]` represents the accuracy scores obtained for each fold during cross-validation.\n",
    "  - Each score indicates the accuracy of predictions made by `classifier` on the respective fold of `X_train` and `y_train`.\n",
    "\n",
    "#### Interpretation\n",
    "- **Evaluation:** \n",
    "  - The scores provide insights into how well `MostFrequentClassClassifier` performs across different subsets of the training data.\n",
    "  - Lower scores might suggest that the model (`classifier`) may not generalize well to unseen data or that improvements could be made to the estimator.\n",
    "\n",
    "#### Conclusion\n",
    "- **Utility:** \n",
    "  - `cross_val_score` facilitates robust evaluation of estimator performance through cross-validation, offering a more reliable assessment compared to a single train-test split.\n",
    "  - Helps in tuning model parameters and assessing its suitability for the given dataset (`X_train`, `y_train`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d973da0f-cd65-433f-add6-e6b636cf9640",
   "metadata": {},
   "source": [
    "### Using Scoing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "187c5e74-7dbc-4c0c-b6bd-15452230baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MostFrequentClassClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.most_frequent_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Ensure y is 1D\n",
    "        y = np.ravel(y)\n",
    "\n",
    "        # Compute the most frequent class\n",
    "        unique_classes, counts = np.unique(y, return_counts=True)\n",
    "        self.most_frequent_ = unique_classes[np.argmax(counts)]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.most_frequent_ is None:\n",
    "            raise ValueError(\"This classifier instance is not fitted yet.\")\n",
    "        # Predict the most frequent class for each input sample\n",
    "        return np.full(shape=(X.shape[0],), fill_value=self.most_frequent_)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"Return the mean accuracy on the given test data and labels.\"\"\"\n",
    "        # Ensure y is 1D\n",
    "        y = np.ravel(y)\n",
    "\n",
    "        # Generate predictions\n",
    "        predictions = self.predict(X)\n",
    "\n",
    "        # Calculate and return the accuracy\n",
    "        return accuracy_score(y, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b034cdd8-0f3d-46ab-b27b-1cc3cf7bbad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the MostFrequentClassClassifier: 0.4\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Simplify to a binary classification problem\n",
    "is_class_0_or_1 = y < 2\n",
    "X_bin = X[is_class_0_or_1]\n",
    "y_bin = y[is_class_0_or_1]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bin, y_bin, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the custom classifier\n",
    "classifier = MostFrequentClassClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier using the score method\n",
    "score = classifier.score(X_test, y_test)\n",
    "print(f\"Accuracy of the MostFrequentClassClassifier: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975da9e-817b-40a3-b89a-86cf47e2d088",
   "metadata": {},
   "source": [
    "### Scoring Function in Custom Estimator\n",
    "\n",
    "#### Definition and Purpose:\n",
    "The `score` method is a crucial part of a custom estimator in scikit-learn. This method is responsible for evaluating the performance of the estimator on given test data and labels. When a custom estimator inherits from `ClassifierMixin`, it gains access to the `score` method, which by default computes the accuracy of the classifier. However, we can override this method to define a custom scoring mechanism if needed.\n",
    "\n",
    "#### Detailed Explanation:\n",
    "\n",
    "**Ensuring Target Vector is 1D:**\n",
    "\n",
    "`y = np.ravel(y)`: Converts the target vector `y` to a 1-dimensional array to ensure compatibility with other scikit-learn functions.\n",
    "\n",
    "**Generating Predictions:**\n",
    "\n",
    "`predictions = self.predict(X)`: Uses the `predict` method of the estimator to generate predictions for the input data `X`.\n",
    "\n",
    "**Calculating Accuracy:**\n",
    "\n",
    "`accuracy_score(y, predictions)`: Computes the accuracy of the predictions by comparing them with the true labels `y`. Accuracy is the ratio of the number of correct predictions to the total number of predictions.\n",
    "\n",
    "**Returning the Accuracy:**\n",
    "\n",
    "The `score` method returns the calculated accuracy, which is a measure of how well the classifier performs on the test data.\n",
    "\n",
    "#### Importance of the `score` Method:\n",
    "\n",
    "**Performance Evaluation:**\n",
    "\n",
    "The `score` method provides a standardized way to evaluate the performance of the custom estimator on unseen data. This is essential for assessing the generalizability of the model.\n",
    "\n",
    "**Integration with scikit-learn Utilities:**\n",
    "\n",
    "By defining the `score` method, the custom estimator becomes compatible with various scikit-learn utilities such as `cross_val_score`, `GridSearchCV`, and `train_test_split`. These utilities rely on the `score` method to evaluate and compare different models.\n",
    "\n",
    "#### Inheritance from `ClassifierMixin`:\n",
    "\n",
    "**Default Scoring Method:**\n",
    "\n",
    "By inheriting from `ClassifierMixin`, the custom estimator inherits a default implementation of the `score` method, which calculates accuracy. This ensures that even without explicitly defining the `score` method, the custom classifier can still be evaluated using scikit-learn's built-in tools.\n",
    "\n",
    "**Flexibility:**\n",
    "\n",
    "While the default scoring method is accuracy, we can override the `score` method to implement custom evaluation metrics tailored to specific needs, providing flexibility in how the model's performance is measured.\n",
    "- eg. calculating f1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "358adf21-0765-4a30-bc2c-fb0bf120d140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of the CustomF1ScoreClassifier: 0.22857142857142856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "class CustomF1ScoreClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.most_frequent_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Ensure y is 1D\n",
    "        y = np.ravel(y)\n",
    "\n",
    "        # Compute the most frequent class\n",
    "        unique_classes, counts = np.unique(y, return_counts=True)\n",
    "        self.most_frequent_ = unique_classes[np.argmax(counts)]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.most_frequent_ is None:\n",
    "            raise ValueError(\"This classifier instance is not fitted yet.\")\n",
    "        # Predict the most frequent class for each input sample\n",
    "        return np.full(shape=(X.shape[0],), fill_value=self.most_frequent_)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"Return the F1 score on the given test data and labels.\"\"\"\n",
    "        # Ensure y is 1D\n",
    "        y = np.ravel(y)\n",
    "\n",
    "        # Generate predictions\n",
    "        predictions = self.predict(X)\n",
    "\n",
    "        # Calculate and return the F1 score\n",
    "        return f1_score(y, predictions, average='weighted')\n",
    "\n",
    "# Load a dataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Simplify to a binary classification problem\n",
    "is_class_0_or_1 = y < 2\n",
    "X_bin = X[is_class_0_or_1]\n",
    "y_bin = y[is_class_0_or_1]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bin, y_bin, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the custom classifier\n",
    "classifier = CustomF1ScoreClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier using the custom score method\n",
    "score = classifier.score(X_test, y_test)\n",
    "print(f\"F1 Score of the CustomF1ScoreClassifier: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453d344-37a9-4ad6-b93a-1548bfb4c631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
